"""
å…¨çƒå¸‚åœºæƒ…ç»ªåˆ†æAgent
åˆ†æå…¨çƒå¸‚åœºæƒ…ç»ªã€VIXæŒ‡æ ‡ã€è·¨èµ„äº§ç›¸å…³æ€§ã€åœ°ç¼˜æ”¿æ²»é£é™©
"""

import asyncio
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from scipy.stats import pearsonr
from collections import defaultdict

from .base_agent import BaseAgent
from data_sources.yahoo_finance import YahooFinanceDataSource
from data_sources.news_source import NewsDataSource
from models.sentiment_data import (
    SentimentAnalysis, SentimentType, RiskLevel, 
    GlobalIndex, VolatilityIndicator, CrossAssetCorrelation,
    MarketRegimeIndicator, FlightToQualitySignal, 
    TechnicalSentiment, SentimentReport, AssetClass
)
from utils.helpers import moving_average, calculate_rsi, calculate_macd


class GlobalSentimentAgent(BaseAgent):
    """å…¨çƒå¸‚åœºæƒ…ç»ªåˆ†æAgent"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("GlobalSentiment", config)
        
        # æ•°æ®æºé…ç½®
        self.yahoo_source = None
        self.news_source = None
        
        # å…¨çƒä¸»è¦æŒ‡æ•°é…ç½®
        self.global_indices = {
            # ç¾å›½ä¸»è¦æŒ‡æ•°
            '^GSPC': {'name': 'S&P 500', 'region': 'US', 'weight': 0.30},
            '^DJI': {'name': 'Dow Jones', 'region': 'US', 'weight': 0.20},
            '^IXIC': {'name': 'NASDAQ', 'region': 'US', 'weight': 0.25},
            
            # å›½é™…ä¸»è¦æŒ‡æ•°
            '^FTSE': {'name': 'FTSE 100', 'region': 'UK', 'weight': 0.08},
            '^GDAXI': {'name': 'DAX', 'region': 'DE', 'weight': 0.08},
            '^N225': {'name': 'Nikkei 225', 'region': 'JP', 'weight': 0.09},
        }
        
        # æ³¢åŠ¨ç‡æŒ‡æ•°
        self.volatility_indices = ['^VIX', '^VVIX', '^VSTOXX']
        
        # é¿é™©èµ„äº§
        self.safe_haven_assets = ['GLD', '^TNX', 'DX-Y.NYB']
        
        # é£é™©èµ„äº§
        self.risk_assets = ['QQQ', 'IWM', 'EEM', 'HYG']
        
        # æƒ…ç»ªæƒé‡é…ç½®
        self.sentiment_weights = {
            'volatility': 0.30,      # æ³¢åŠ¨ç‡æŒ‡æ ‡
            'correlations': 0.25,    # è·¨èµ„äº§ç›¸å…³æ€§
            'news_sentiment': 0.20,  # æ–°é—»æƒ…ç»ª
            'technical': 0.15,       # æŠ€æœ¯æŒ‡æ ‡
            'flight_to_quality': 0.10 # é¿é™©æµåŠ¨
        }
        
    async def initialize(self) -> None:
        """åˆå§‹åŒ–GlobalSentiment Agent"""
        
        # åˆå§‹åŒ–æ•°æ®æº
        self.yahoo_source = YahooFinanceDataSource(self.config)
        await self.yahoo_source.initialize()
        
        self.news_source = NewsDataSource(self.config)
        await self.news_source.initialize()
        
        self.logger.info("GlobalSentiment Agentåˆå§‹åŒ–å®Œæˆ")
        
    async def fetch_data(self) -> Dict[str, Any]:
        """è·å–å…¨çƒå¸‚åœºæƒ…ç»ªåˆ†ææ‰€éœ€æ•°æ®"""
        
        try:
            # å¹¶è¡Œè·å–å„ç±»æ•°æ®
            tasks = [
                self._fetch_global_indices_data(),
                self._fetch_volatility_data(),
                self._fetch_safe_haven_data(),
                self._fetch_risk_assets_data(),
                self._fetch_news_sentiment_data()
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            global_indices, volatility_data, safe_haven_data, risk_assets_data, news_data = results
            
            return {
                'timestamp': datetime.now(),
                'global_indices': global_indices if not isinstance(global_indices, Exception) else [],
                'volatility_data': volatility_data if not isinstance(volatility_data, Exception) else [],
                'safe_haven_data': safe_haven_data if not isinstance(safe_haven_data, Exception) else [],
                'risk_assets_data': risk_assets_data if not isinstance(risk_assets_data, Exception) else [],
                'news_data': news_data if not isinstance(news_data, Exception) else {'news_sentiment': []},
                'total_data_points': len(global_indices or []) + len(volatility_data or [])
            }
            
        except Exception as e:
            self.logger.error(f"è·å–å…¨çƒæƒ…ç»ªæ•°æ®å¤±è´¥: {e}")
            return {'timestamp': datetime.now(), 'error': str(e)}
            
    async def _fetch_global_indices_data(self) -> List[GlobalIndex]:
        """è·å–å…¨çƒä¸»è¦æŒ‡æ•°æ•°æ®"""
        try:
            symbols = list(self.global_indices.keys())
            data = await self.yahoo_source.fetch_data(symbols, data_type='quote')
            
            indices = []
            for data_point in data.get('data', []):
                symbol = data_point.symbol
                if symbol in self.global_indices:
                    config = self.global_indices[symbol]
                    
                    index = GlobalIndex(
                        symbol=symbol,
                        name=config['name'],
                        value=data_point.price,
                        change=data_point.change or 0,
                        change_percent=data_point.change_percent or 0,
                        volume=data_point.volume,
                        market_cap=None,
                        region=config['region'],
                        sector=None,
                        timestamp=data_point.timestamp
                    )
                    indices.append(index)
                    
            return indices
            
        except Exception as e:
            self.logger.error(f"è·å–å…¨çƒæŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return []
            
    async def _fetch_volatility_data(self) -> List[VolatilityIndicator]:
        """è·å–æ³¢åŠ¨ç‡æŒ‡æ ‡æ•°æ®"""
        try:
            data = await self.yahoo_source.fetch_data(self.volatility_indices, data_type='quote')
            
            indicators = []
            for data_point in data.get('data', []):
                # è·å–å†å²æ•°æ®è®¡ç®—ç™¾åˆ†ä½
                hist_data = await self.yahoo_source.fetch_data(
                    [data_point.symbol], 
                    data_type='history', 
                    period='1y'
                )
                
                percentile_rank = self._calculate_percentile_rank(
                    data_point.price, hist_data.get('data', [])
                )
                
                interpretation = self._interpret_volatility(data_point.price, percentile_rank)
                
                indicator = VolatilityIndicator(
                    symbol=data_point.symbol,
                    name=self._get_volatility_name(data_point.symbol),
                    value=data_point.price,
                    change=data_point.change or 0,
                    change_percent=data_point.change_percent or 0,
                    percentile_rank=percentile_rank,
                    interpretation=interpretation,
                    timestamp=data_point.timestamp
                )
                indicators.append(indicator)
                
            return indicators
            
        except Exception as e:
            self.logger.error(f"è·å–æ³¢åŠ¨ç‡æ•°æ®å¤±è´¥: {e}")
            return []
            
    async def _fetch_safe_haven_data(self) -> List[Dict[str, Any]]:
        """è·å–é¿é™©èµ„äº§æ•°æ®"""
        try:
            data = await self.yahoo_source.fetch_data(self.safe_haven_assets, data_type='quote')
            return data.get('data', [])
        except Exception as e:
            self.logger.error(f"è·å–é¿é™©èµ„äº§æ•°æ®å¤±è´¥: {e}")
            return []
            
    async def _fetch_risk_assets_data(self) -> List[Dict[str, Any]]:
        """è·å–é£é™©èµ„äº§æ•°æ®"""
        try:
            data = await self.yahoo_source.fetch_data(self.risk_assets, data_type='quote')
            return data.get('data', [])
        except Exception as e:
            self.logger.error(f"è·å–é£é™©èµ„äº§æ•°æ®å¤±è´¥: {e}")
            return []
            
    async def _fetch_news_sentiment_data(self) -> Dict[str, Any]:
        """è·å–æ–°é—»æƒ…ç»ªæ•°æ®"""
        try:
            return await self.news_source.fetch_data(hours_back=24, max_articles=50)
        except Exception as e:
            self.logger.error(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return {'news_sentiment': []}
            
    async def analyze(self, data: Dict[str, Any]) -> SentimentAnalysis:
        """åˆ†æå…¨çƒå¸‚åœºæƒ…ç»ª"""
        
        try:
            # åˆ†æå„ä¸ªç»„ä»¶
            volatility_sentiment = self._analyze_volatility_sentiment(data.get('volatility_data', []))
            correlation_sentiment = await self._analyze_correlation_sentiment(data)
            news_sentiment = self._analyze_news_sentiment(data.get('news_data', {}))
            technical_sentiment = await self._analyze_technical_sentiment(data)
            flight_to_quality = self._analyze_flight_to_quality(data)
            
            # ç»¼åˆè®¡ç®—æƒ…ç»ªåˆ†æ•°
            sentiment_components = {
                'volatility': volatility_sentiment,
                'correlations': correlation_sentiment,
                'news_sentiment': news_sentiment,
                'technical': technical_sentiment,
                'flight_to_quality': flight_to_quality
            }
            
            overall_sentiment_score = self._calculate_weighted_sentiment(sentiment_components)
            overall_sentiment_type = self._determine_sentiment_type(overall_sentiment_score)
            risk_level = self._assess_risk_level(sentiment_components)
            
            # è®¡ç®—åˆ†ç±»æƒ…ç»ª
            asset_sentiments = self._calculate_asset_class_sentiments(data)
            
            # ç”Ÿæˆå…³é”®æŒ‡æ ‡
            fear_greed_index = self._calculate_fear_greed_index(sentiment_components)
            volatility_regime = self._determine_volatility_regime(data.get('volatility_data', []))
            correlation_regime = self._determine_correlation_regime(correlation_sentiment)
            
            # è¯†åˆ«é©±åŠ¨å› ç´ å’Œé£é™©
            primary_drivers = self._identify_primary_drivers(sentiment_components, data)
            risk_factors = self._identify_risk_factors(sentiment_components, data)
            opportunities = self._identify_opportunities(sentiment_components, data)
            
            # ç”Ÿæˆé¢„æµ‹å’Œå»ºè®®
            short_term_outlook = self._generate_short_term_outlook(sentiment_components)
            medium_term_outlook = self._generate_medium_term_outlook(sentiment_components)
            positioning = self._recommend_positioning(sentiment_components, risk_level)
            hedges = self._suggest_hedges(risk_level, sentiment_components)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(sentiment_components, data)
            
            return SentimentAnalysis(
                overall_sentiment=overall_sentiment_type,
                sentiment_score=overall_sentiment_score,
                confidence=confidence,
                risk_level=risk_level,
                
                # åˆ†ç±»æƒ…ç»ª
                equity_sentiment=asset_sentiments['equity'],
                bond_sentiment=asset_sentiments['bond'],
                commodity_sentiment=asset_sentiments['commodity'],
                currency_sentiment=asset_sentiments['currency'],
                
                # å…³é”®æŒ‡æ ‡
                fear_greed_index=fear_greed_index,
                volatility_regime=volatility_regime,
                correlation_regime=correlation_regime,
                
                # é©±åŠ¨å› ç´ 
                primary_drivers=primary_drivers,
                risk_factors=risk_factors,
                opportunities=opportunities,
                
                # é¢„æµ‹å’Œå»ºè®®
                short_term_outlook=short_term_outlook,
                medium_term_outlook=medium_term_outlook,
                recommended_positioning=positioning,
                hedge_suggestions=hedges,
                
                analysis_timestamp=datetime.now(),
                next_update=datetime.now() + timedelta(hours=4)
            )
            
        except Exception as e:
            self.logger.error(f"å…¨çƒæƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return self._create_default_analysis()
            
    def _analyze_volatility_sentiment(self, volatility_data: List[VolatilityIndicator]) -> float:
        """åˆ†ææ³¢åŠ¨ç‡æƒ…ç»ª"""
        if not volatility_data:
            return 0.0
            
        vix_score = 0.0
        
        for indicator in volatility_data:
            if indicator.symbol == '^VIX':
                # VIXè§£è¯»ï¼šä½äº20ä¸ºä½æ³¢åŠ¨ç‡ï¼Œ20-30ä¸ºæ­£å¸¸ï¼Œ30ä»¥ä¸Šä¸ºé«˜æ³¢åŠ¨ç‡
                if indicator.value < 20:
                    vix_score = 0.3  # ä¹è§‚
                elif indicator.value < 30:
                    vix_score = 0.0  # ä¸­æ€§
                else:
                    vix_score = -0.5  # æ‚²è§‚
                    
                # è€ƒè™‘ç™¾åˆ†ä½æ’å
                if indicator.percentile_rank > 80:
                    vix_score -= 0.2  # æ›´æ‚²è§‚
                elif indicator.percentile_rank < 20:
                    vix_score += 0.2  # æ›´ä¹è§‚
                    
                break
                
        return max(-1.0, min(1.0, vix_score))
        
    async def _analyze_correlation_sentiment(self, data: Dict[str, Any]) -> float:
        """åˆ†æè·¨èµ„äº§ç›¸å…³æ€§æƒ…ç»ª"""
        try:
            # è·å–ä¸»è¦èµ„äº§çš„å†å²æ•°æ®è®¡ç®—ç›¸å…³æ€§
            symbols = ['^GSPC', 'GLD', '^TNX', 'DX-Y.NYB']
            correlations = []
            
            for i, symbol1 in enumerate(symbols):
                for symbol2 in symbols[i+1:]:
                    correlation = await self._calculate_correlation(symbol1, symbol2)
                    if correlation is not None:
                        correlations.append(abs(correlation))  # ä½¿ç”¨ç»å¯¹å€¼
                        
            if not correlations:
                return 0.0
                
            avg_correlation = np.mean(correlations)
            
            # é«˜ç›¸å…³æ€§é€šå¸¸è¡¨ç¤ºææ…Œæƒ…ç»ªï¼ˆæ‰€æœ‰èµ„äº§åŒå‘å˜åŠ¨ï¼‰
            if avg_correlation > 0.7:
                return -0.4  # ææ…Œ
            elif avg_correlation > 0.5:
                return -0.2  # è½»å¾®ææ…Œ
            elif avg_correlation < 0.3:
                return 0.2   # æ­£å¸¸åˆ†åŒ–
            else:
                return 0.0   # ä¸­æ€§
                
        except Exception as e:
            self.logger.error(f"ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
            return 0.0
            
    def _analyze_news_sentiment(self, news_data: Dict[str, Any]) -> float:
        """åˆ†ææ–°é—»æƒ…ç»ª"""
        news_articles = news_data.get('news_sentiment', [])
        
        if not news_articles:
            return 0.0
            
        # åŠ æƒå¹³å‡æ–°é—»æƒ…ç»ª
        total_weight = 0
        weighted_sentiment = 0
        
        for article in news_articles:
            weight = article.importance * article.market_relevance
            weighted_sentiment += article.sentiment_score * weight
            total_weight += weight
            
        if total_weight == 0:
            return 0.0
            
        return weighted_sentiment / total_weight
        
    async def _analyze_technical_sentiment(self, data: Dict[str, Any]) -> float:
        """åˆ†ææŠ€æœ¯é¢æƒ…ç»ª"""
        try:
            # åˆ†æä¸»è¦æŒ‡æ•°çš„æŠ€æœ¯æŒ‡æ ‡
            indices = data.get('global_indices', [])
            if not indices:
                return 0.0
                
            technical_scores = []
            
            for index in indices:
                # è·å–å†å²æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                hist_data = await self.yahoo_source.fetch_data(
                    [index.symbol], 
                    data_type='history',
                    period='3mo'
                )
                
                if hist_data.get('data'):
                    prices = [point.close for point in hist_data['data']]
                    
                    # è®¡ç®—RSI
                    rsi = calculate_rsi(prices)
                    if rsi:
                        if rsi[-1] > 70:
                            technical_scores.append(-0.3)  # è¶…ä¹°
                        elif rsi[-1] < 30:
                            technical_scores.append(0.3)   # è¶…å–
                        else:
                            technical_scores.append(0.0)   # ä¸­æ€§
                            
            return np.mean(technical_scores) if technical_scores else 0.0
            
        except Exception as e:
            self.logger.error(f"æŠ€æœ¯åˆ†æå¤±è´¥: {e}")
            return 0.0
            
    def _analyze_flight_to_quality(self, data: Dict[str, Any]) -> float:
        """åˆ†æé¿é™©æµåŠ¨æƒ…ç»ª"""
        safe_haven_data = data.get('safe_haven_data', [])
        risk_assets_data = data.get('risk_assets_data', [])
        
        if not safe_haven_data or not risk_assets_data:
            return 0.0
            
        # è®¡ç®—é¿é™©èµ„äº§å’Œé£é™©èµ„äº§çš„å¹³å‡è¡¨ç°
        safe_haven_performance = np.mean([asset.change_percent or 0 for asset in safe_haven_data])
        risk_assets_performance = np.mean([asset.change_percent or 0 for asset in risk_assets_data])
        
        # é¿é™©èµ„äº§è¡¨ç°å¥½äºé£é™©èµ„äº§æ—¶ï¼Œè¡¨ç¤ºææ…Œæƒ…ç»ª
        performance_diff = safe_haven_performance - risk_assets_performance
        
        # å½’ä¸€åŒ–åˆ°-1åˆ°1èŒƒå›´
        return max(-1.0, min(1.0, performance_diff / 5.0))
        
    def _calculate_weighted_sentiment(self, components: Dict[str, float]) -> float:
        """è®¡ç®—åŠ æƒæƒ…ç»ªåˆ†æ•°"""
        weighted_sum = 0.0
        
        for component, score in components.items():
            weight = self.sentiment_weights.get(component, 0.0)
            weighted_sum += score * weight
            
        return max(-1.0, min(1.0, weighted_sum))
        
    def _determine_sentiment_type(self, sentiment_score: float) -> SentimentType:
        """ç¡®å®šæƒ…ç»ªç±»å‹"""
        if sentiment_score > 0.3:
            return SentimentType.GREED
        elif sentiment_score < -0.3:
            return SentimentType.FEAR
        elif abs(sentiment_score) < 0.1:
            return SentimentType.NEUTRAL
        else:
            return SentimentType.UNCERTAINTY
            
    def _assess_risk_level(self, components: Dict[str, float]) -> RiskLevel:
        """è¯„ä¼°é£é™©çº§åˆ«"""
        # åŸºäºå„ç»„ä»¶çš„ææ…Œç¨‹åº¦è¯„ä¼°é£é™©
        fear_components = sum(1 for score in components.values() if score < -0.2)
        extreme_fear = sum(1 for score in components.values() if score < -0.5)
        
        if extreme_fear >= 2:
            return RiskLevel.EXTREME
        elif fear_components >= 3:
            return RiskLevel.HIGH
        elif fear_components >= 2:
            return RiskLevel.MEDIUM
        else:
            return RiskLevel.LOW
            
    def _calculate_asset_class_sentiments(self, data: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—å„èµ„äº§ç±»åˆ«æƒ…ç»ª"""
        indices = data.get('global_indices', [])
        
        # è®¡ç®—è‚¡ç¥¨æƒ…ç»ªï¼ˆåŸºäºæŒ‡æ•°è¡¨ç°ï¼‰
        equity_performance = []
        for index in indices:
            if index.region in ['US', 'UK', 'DE', 'JP']:
                equity_performance.append(index.change_percent)
                
        equity_sentiment = np.mean(equity_performance) / 2.0 if equity_performance else 0.0
        
        # å€ºåˆ¸æƒ…ç»ªï¼ˆåŸºäºæ”¶ç›Šç‡å˜åŒ–ï¼Œç®€åŒ–å¤„ç†ï¼‰
        bond_sentiment = 0.0  # éœ€è¦å€ºåˆ¸æ•°æ®
        
        # å•†å“æƒ…ç»ªï¼ˆåŸºäºé¿é™©èµ„äº§è¡¨ç°ï¼‰
        safe_haven_data = data.get('safe_haven_data', [])
        commodity_sentiment = 0.0
        for asset in safe_haven_data:
            if asset.symbol == 'GLD':  # é»„é‡‘
                commodity_sentiment = (asset.change_percent or 0) / 2.0
                break
                
        # è´§å¸æƒ…ç»ªï¼ˆåŸºäºç¾å…ƒæŒ‡æ•°ï¼‰
        currency_sentiment = 0.0
        for asset in safe_haven_data:
            if asset.symbol == 'DX-Y.NYB':  # ç¾å…ƒæŒ‡æ•°
                currency_sentiment = (asset.change_percent or 0) / 2.0
                break
                
        return {
            'equity': max(-1.0, min(1.0, equity_sentiment)),
            'bond': bond_sentiment,
            'commodity': max(-1.0, min(1.0, commodity_sentiment)),
            'currency': max(-1.0, min(1.0, currency_sentiment))
        }
        
    def _calculate_fear_greed_index(self, components: Dict[str, float]) -> float:
        """è®¡ç®—ææƒ§è´ªå©ªæŒ‡æ•°ï¼ˆ0-100ï¼Œ50ä¸ºä¸­æ€§ï¼‰"""
        # å°†-1åˆ°1çš„æƒ…ç»ªåˆ†æ•°è½¬æ¢ä¸º0-100çš„æŒ‡æ•°
        avg_sentiment = np.mean(list(components.values()))
        fear_greed = 50 + (avg_sentiment * 50)
        return max(0.0, min(100.0, fear_greed))
        
    def _determine_volatility_regime(self, volatility_data: List[VolatilityIndicator]) -> str:
        """ç¡®å®šæ³¢åŠ¨ç‡åˆ¶åº¦"""
        if not volatility_data:
            return "unknown"
            
        for indicator in volatility_data:
            if indicator.symbol == '^VIX':
                if indicator.value < 15:
                    return "low"
                elif indicator.value < 20:
                    return "normal"
                elif indicator.value < 30:
                    return "elevated"
                else:
                    return "extreme"
                    
        return "normal"
        
    def _determine_correlation_regime(self, correlation_sentiment: float) -> str:
        """ç¡®å®šç›¸å…³æ€§åˆ¶åº¦"""
        if correlation_sentiment < -0.3:
            return "crisis"
        elif correlation_sentiment < -0.1:
            return "elevated"
        else:
            return "normal"
            
    def _identify_primary_drivers(self, components: Dict[str, float], data: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«ä¸»è¦é©±åŠ¨å› ç´ """
        drivers = []
        
        # æ ¹æ®å„ç»„ä»¶çš„å¼ºåº¦è¯†åˆ«é©±åŠ¨å› ç´ 
        if abs(components.get('volatility', 0)) > 0.3:
            drivers.append("æ³¢åŠ¨ç‡å¼‚å¸¸" if components['volatility'] < 0 else "æ³¢åŠ¨ç‡æ­£å¸¸åŒ–")
            
        if abs(components.get('news_sentiment', 0)) > 0.2:
            drivers.append("æ–°é—»äº‹ä»¶å½±å“" if components['news_sentiment'] < 0 else "æ­£é¢æ–°é—»æ¨åŠ¨")
            
        if abs(components.get('correlations', 0)) > 0.2:
            drivers.append("èµ„äº§é«˜åº¦ç›¸å…³" if components['correlations'] < 0 else "èµ„äº§æ­£å¸¸åˆ†åŒ–")
            
        if abs(components.get('flight_to_quality', 0)) > 0.2:
            drivers.append("é¿é™©æƒ…ç»ªä¸Šå‡" if components['flight_to_quality'] < 0 else "é£é™©åå¥½å›å‡")
            
        if not drivers:
            drivers.append("å¸‚åœºæƒ…ç»ªç›¸å¯¹ç¨³å®š")
            
        return drivers[:3]  # æœ€å¤šè¿”å›3ä¸ªä¸»è¦é©±åŠ¨å› ç´ 
        
    def _identify_risk_factors(self, components: Dict[str, float], data: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«é£é™©å› ç´ """
        risks = []
        
        # æ³¢åŠ¨ç‡é£é™©
        if components.get('volatility', 0) < -0.3:
            risks.append("æ³¢åŠ¨ç‡é£™å‡é£é™©")
            
        # ç›¸å…³æ€§é£é™©
        if components.get('correlations', 0) < -0.2:
            risks.append("èµ„äº§ç›¸å…³æ€§è¿‡é«˜")
            
        # æ–°é—»é£é™©
        news_data = data.get('news_data', {})
        negative_news = sum(1 for article in news_data.get('news_sentiment', []) 
                          if article.sentiment_score < -0.3 and article.importance > 0.5)
        if negative_news >= 3:
            risks.append("é‡è¦è´Ÿé¢æ–°é—»å¢å¤š")
            
        # åœ°ç¼˜æ”¿æ²»é£é™©
        geo_events = data.get('news_data', {}).get('geopolitical_events', [])
        high_risk_events = sum(1 for event in geo_events if event.severity in [RiskLevel.HIGH, RiskLevel.EXTREME])
        if high_risk_events > 0:
            risks.append("åœ°ç¼˜æ”¿æ²»é£é™©äº‹ä»¶")
            
        return risks
        
    def _identify_opportunities(self, components: Dict[str, float], data: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«æŠ•èµ„æœºä¼š"""
        opportunities = []
        
        # ä½æ³¢åŠ¨ç‡æœºä¼š
        if components.get('volatility', 0) > 0.2:
            opportunities.append("ä½æ³¢åŠ¨ç‡ç¯å¢ƒï¼Œé€‚åˆé£é™©èµ„äº§é…ç½®")
            
        # æ­£é¢æƒ…ç»ªæœºä¼š
        if components.get('news_sentiment', 0) > 0.2:
            opportunities.append("æ­£é¢æ–°é—»æ¨åŠ¨ï¼Œå…³æ³¨æˆé•¿æ€§èµ„äº§")
            
        # åˆ†åŒ–æœºä¼š
        if components.get('correlations', 0) > 0.1:
            opportunities.append("èµ„äº§åˆ†åŒ–è‰¯å¥½ï¼Œé€‚åˆç²¾é€‰ä¸ªè‚¡")
            
        # é¿é™©æœºä¼š
        if components.get('flight_to_quality', 0) < -0.2:
            opportunities.append("é¿é™©éœ€æ±‚å¼ºçƒˆï¼Œå…³æ³¨é˜²å¾¡æ€§é…ç½®")
            
        return opportunities
        
    def _generate_short_term_outlook(self, components: Dict[str, float]) -> str:
        """ç”ŸæˆçŸ­æœŸå±•æœ›"""
        avg_sentiment = np.mean(list(components.values()))
        
        if avg_sentiment > 0.2:
            return "çŸ­æœŸå†…å¸‚åœºæƒ…ç»ªç›¸å¯¹ä¹è§‚ï¼Œé£é™©èµ„äº§å¯èƒ½ç»§ç»­å—ç›Š"
        elif avg_sentiment < -0.2:
            return "çŸ­æœŸå†…ææ…Œæƒ…ç»ªå¯èƒ½æŒç»­ï¼Œå»ºè®®å…³æ³¨é¿é™©èµ„äº§"
        else:
            return "çŸ­æœŸå†…å¸‚åœºæƒ…ç»ªä¸­æ€§ï¼Œé¢„è®¡éœ‡è¡æ•´ç†æ ¼å±€"
            
    def _generate_medium_term_outlook(self, components: Dict[str, float]) -> str:
        """ç”Ÿæˆä¸­æœŸå±•æœ›"""
        volatility_level = abs(components.get('volatility', 0))
        
        if volatility_level > 0.3:
            return "ä¸­æœŸå†…æ³¢åŠ¨ç‡å¯èƒ½ä¿æŒé«˜ä½ï¼Œéœ€è¦åŠ¨æ€è°ƒæ•´é…ç½®"
        else:
            return "ä¸­æœŸå†…å¸‚åœºå¯èƒ½å›å½’åŸºæœ¬é¢é©±åŠ¨ï¼Œå…³æ³¨ç»æµæ•°æ®è¡¨ç°"
            
    def _recommend_positioning(self, components: Dict[str, float], risk_level: RiskLevel) -> List[str]:
        """æ¨èä»“ä½é…ç½®"""
        recommendations = []
        
        if risk_level in [RiskLevel.HIGH, RiskLevel.EXTREME]:
            recommendations.extend([
                "å‡å°‘é£é™©èµ„äº§æ•å£",
                "å¢åŠ ç°é‡‘å’ŒçŸ­æœŸå€ºåˆ¸é…ç½®",
                "è€ƒè™‘é˜²å¾¡æ€§è‚¡ç¥¨"
            ])
        elif risk_level == RiskLevel.MEDIUM:
            recommendations.extend([
                "ç»´æŒç›¸å¯¹å‡è¡¡é…ç½®",
                "é€‚åº¦é™ä½æ æ†æ°´å¹³",
                "å…³æ³¨é«˜è´¨é‡èµ„äº§"
            ])
        else:
            recommendations.extend([
                "å¯é€‚åº¦å¢åŠ é£é™©èµ„äº§é…ç½®",
                "å…³æ³¨æˆé•¿æ€§æŠ•èµ„æœºä¼š",
                "è€ƒè™‘æ–°å…´å¸‚åœºèµ„äº§"
            ])
            
        return recommendations[:3]
        
    def _suggest_hedges(self, risk_level: RiskLevel, components: Dict[str, float]) -> List[str]:
        """å»ºè®®å¯¹å†²ç­–ç•¥"""
        hedges = []
        
        if risk_level >= RiskLevel.MEDIUM:
            hedges.append("VIXçœ‹æ¶¨æœŸæƒå¯¹å†²æ³¢åŠ¨ç‡é£é™©")
            
        if components.get('correlations', 0) < -0.2:
            hedges.append("è·¨èµ„äº§å¯¹å†²ç­–ç•¥")
            
        if components.get('flight_to_quality', 0) < -0.2:
            hedges.append("å¢åŠ é»„é‡‘ç­‰é¿é™©èµ„äº§é…ç½®")
            
        if not hedges:
            hedges.append("å½“å‰é£é™©å¯æ§ï¼Œæ— éœ€ç‰¹æ®Šå¯¹å†²")
            
        return hedges
        
    def _calculate_confidence(self, components: Dict[str, float], data: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        confidence = 0.0
        
        # æ•°æ®å®Œæ•´æ€§
        data_completeness = 0.0
        total_sources = 5  # é¢„æœŸæ•°æ®æºæ•°é‡
        
        if data.get('global_indices'):
            data_completeness += 0.2
        if data.get('volatility_data'):
            data_completeness += 0.2
        if data.get('safe_haven_data'):
            data_completeness += 0.2
        if data.get('risk_assets_data'):
            data_completeness += 0.2
        if data.get('news_data', {}).get('news_sentiment'):
            data_completeness += 0.2
            
        confidence += data_completeness * 0.4
        
        # ä¿¡å·ä¸€è‡´æ€§
        signal_consistency = 1.0 - np.std(list(components.values()))
        confidence += signal_consistency * 0.3
        
        # æ•°æ®æ–°é²œåº¦
        current_hour = datetime.now().hour
        if 9 <= current_hour <= 16:  # äº¤æ˜“æ—¶é—´å†…
            confidence += 0.3
        else:
            confidence += 0.15
            
        return max(0.0, min(1.0, confidence))
        
    async def generate_report(self, analysis: SentimentAnalysis) -> str:
        """ç”Ÿæˆå…¨çƒæƒ…ç»ªåˆ†ææŠ¥å‘Š"""
        
        timestamp = analysis.analysis_timestamp.strftime("%Y-%m-%d %H:%M")
        
        # æƒ…ç»ªæè¿°
        sentiment_desc = {
            SentimentType.FEAR: "ææ…Œ",
            SentimentType.GREED: "è´ªå©ª", 
            SentimentType.NEUTRAL: "ä¸­æ€§",
            SentimentType.UNCERTAINTY: "ä¸ç¡®å®š"
        }[analysis.overall_sentiment]
        
        # é£é™©çº§åˆ«æè¿°
        risk_desc = {
            RiskLevel.LOW: "ä½é£é™©",
            RiskLevel.MEDIUM: "ä¸­ç­‰é£é™©",
            RiskLevel.HIGH: "é«˜é£é™©", 
            RiskLevel.EXTREME: "æç«¯é£é™©"
        }[analysis.risk_level]
        
        report = f"""
# å…¨çƒå¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š

## ğŸ“Š ç»¼åˆæƒ…ç»ªè¯„ä¼°
**æ•´ä½“æƒ…ç»ª**: {sentiment_desc}
**æƒ…ç»ªåˆ†æ•°**: {analysis.sentiment_score:+.3f} (-1ææ…Œ, +1è´ªå©ª)
**åˆ†æç½®ä¿¡åº¦**: {analysis.confidence:.1%}
**é£é™©çº§åˆ«**: {risk_desc}

## ğŸŒ åˆ†ç±»èµ„äº§æƒ…ç»ª
â€¢ è‚¡ç¥¨å¸‚åœº: {analysis.equity_sentiment:+.2f}
â€¢ å€ºåˆ¸å¸‚åœº: {analysis.bond_sentiment:+.2f}
â€¢ å•†å“å¸‚åœº: {analysis.commodity_sentiment:+.2f}
â€¢ è´§å¸å¸‚åœº: {analysis.currency_sentiment:+.2f}

## ğŸ“ˆ å¸‚åœºçŠ¶æ€æŒ‡æ ‡
â€¢ ææƒ§è´ªå©ªæŒ‡æ•°: {analysis.fear_greed_index:.0f}/100
â€¢ æ³¢åŠ¨ç‡ç¯å¢ƒ: {analysis.volatility_regime}
â€¢ ç›¸å…³æ€§çŠ¶æ€: {analysis.correlation_regime}

## ğŸ” ä¸»è¦é©±åŠ¨å› ç´ 
{chr(10).join(f"â€¢ {driver}" for driver in analysis.primary_drivers)}

## âš ï¸ é£é™©å› ç´ 
{chr(10).join(f"â€¢ {risk}" for risk in analysis.risk_factors) if analysis.risk_factors else "â€¢ å½“å‰æœªè¯†åˆ«å‡ºé‡å¤§é£é™©å› ç´ "}

## ğŸ’¡ æŠ•èµ„æœºä¼š
{chr(10).join(f"â€¢ {opp}" for opp in analysis.opportunities) if analysis.opportunities else "â€¢ å¸‚åœºæœºä¼šæœ‰é™ï¼Œå»ºè®®è°¨æ…æ“ä½œ"}

## ğŸ”® å¸‚åœºå±•æœ›
**çŸ­æœŸé¢„æœŸ**: {analysis.short_term_outlook}
**ä¸­æœŸé¢„æœŸ**: {analysis.medium_term_outlook}

## ğŸ’¼ é…ç½®å»ºè®®
{chr(10).join(f"â€¢ {rec}" for rec in analysis.recommended_positioning)}

## ğŸ›¡ï¸ å¯¹å†²å»ºè®®
{chr(10).join(f"â€¢ {hedge}" for hedge in analysis.hedge_suggestions)}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {timestamp}*
*ä¸‹æ¬¡æ›´æ–°: {analysis.next_update.strftime("%Y-%m-%d %H:%M")}*
"""
        
        return report
        
    # è¾…åŠ©æ–¹æ³•
    def _calculate_percentile_rank(self, current_value: float, historical_data: List[Any]) -> float:
        """è®¡ç®—å½“å‰å€¼åœ¨å†å²æ•°æ®ä¸­çš„ç™¾åˆ†ä½æ’å"""
        if not historical_data:
            return 50.0  # é»˜è®¤ä¸­ä½æ•°
            
        values = [point.close for point in historical_data if hasattr(point, 'close')]
        if not values:
            return 50.0
            
        values.append(current_value)
        values.sort()
        
        rank = values.index(current_value) / len(values) * 100
        return rank
        
    def _interpret_volatility(self, value: float, percentile_rank: float) -> str:
        """è§£è¯»æ³¢åŠ¨ç‡æŒ‡æ ‡"""
        if value < 15:
            return "æä½æ³¢åŠ¨ç‡ï¼Œå¸‚åœºè¿‡åº¦è‡ªæ»¡"
        elif value < 20:
            return "ä½æ³¢åŠ¨ç‡ï¼Œå¸‚åœºæƒ…ç»ªç¨³å®š"
        elif value < 30:
            return "æ­£å¸¸æ³¢åŠ¨ç‡ï¼Œå¸‚åœºè¿è¡Œå¥åº·"
        elif value < 40:
            return "é«˜æ³¢åŠ¨ç‡ï¼Œå¸‚åœºå­˜åœ¨æ‹…å¿§"
        else:
            return "æé«˜æ³¢åŠ¨ç‡ï¼Œå¸‚åœºææ…Œæƒ…ç»ªä¸¥é‡"
            
    def _get_volatility_name(self, symbol: str) -> str:
        """è·å–æ³¢åŠ¨ç‡æŒ‡æ ‡åç§°"""
        names = {
            '^VIX': 'æ ‡æ™®500æ³¢åŠ¨ç‡æŒ‡æ•°',
            '^VVIX': 'VIXæ³¢åŠ¨ç‡æŒ‡æ•°',
            '^VSTOXX': 'æ¬§æ´²è‚¡æŒ‡æ³¢åŠ¨ç‡'
        }
        return names.get(symbol, symbol)
        
    async def _calculate_correlation(self, symbol1: str, symbol2: str, period: str = '3mo') -> Optional[float]:
        """è®¡ç®—ä¸¤ä¸ªèµ„äº§çš„ç›¸å…³æ€§"""
        try:
            # è·å–å†å²æ•°æ®
            data1 = await self.yahoo_source.fetch_data([symbol1], data_type='history', period=period)
            data2 = await self.yahoo_source.fetch_data([symbol2], data_type='history', period=period)
            
            prices1 = [point.close for point in data1.get('data', [])]
            prices2 = [point.close for point in data2.get('data', [])]
            
            if len(prices1) < 10 or len(prices2) < 10:
                return None
                
            # è®¡ç®—æ”¶ç›Šç‡
            returns1 = np.diff(prices1) / prices1[:-1]
            returns2 = np.diff(prices2) / prices2[:-1]
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            min_length = min(len(returns1), len(returns2))
            returns1 = returns1[:min_length]
            returns2 = returns2[:min_length]
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            correlation, _ = pearsonr(returns1, returns2)
            
            return correlation if not np.isnan(correlation) else None
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—ç›¸å…³æ€§å¤±è´¥ {symbol1}-{symbol2}: {e}")
            return None
            
    def _create_default_analysis(self) -> SentimentAnalysis:
        """åˆ›å»ºé»˜è®¤åˆ†æç»“æœ"""
        return SentimentAnalysis(
            overall_sentiment=SentimentType.NEUTRAL,
            sentiment_score=0.0,
            confidence=0.5,
            risk_level=RiskLevel.MEDIUM,
            equity_sentiment=0.0,
            bond_sentiment=0.0,
            commodity_sentiment=0.0,
            currency_sentiment=0.0,
            fear_greed_index=50.0,
            volatility_regime="normal",
            correlation_regime="normal",
            primary_drivers=["æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æ"],
            risk_factors=["æ•°æ®è·å–å¼‚å¸¸"],
            opportunities=["ç­‰å¾…æ•°æ®å®Œæ•´åå†è¯„ä¼°"],
            short_term_outlook="æ•°æ®ä¸è¶³ï¼Œæš‚æ— é¢„æµ‹",
            medium_term_outlook="æ•°æ®ä¸è¶³ï¼Œæš‚æ— é¢„æµ‹",
            recommended_positioning=["ç­‰å¾…æ•°æ®å®Œæ•´"],
            hedge_suggestions=["æ•°æ®ä¸è¶³æ—¶å»ºè®®ä¿å®ˆæ“ä½œ"],
            analysis_timestamp=datetime.now(),
            next_update=datetime.now() + timedelta(hours=1)
        )
        
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        if self.yahoo_source:
            await self.yahoo_source.cleanup()
        if self.news_source:
            await self.news_source.cleanup()
            
        self.logger.info("GlobalSentiment Agentæ¸…ç†å®Œæˆ")
        
    def get_dependencies(self) -> List[str]:
        """è·å–ä¾èµ–çš„å…¶ä»–Agent"""
        return []  # ç‹¬ç«‹Agentï¼Œä¸ä¾èµ–å…¶ä»–Agent 